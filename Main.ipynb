{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from mnist import MNIST\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "#from sklearn.model_selection import StratifiedKFold\n",
    "# from tensorflow import keras\n",
    "from keras.models import load_model\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D\n",
    "from keras.layers import MaxPooling2D\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Flatten\n",
    "from keras.optimizers import SGD\n",
    "#import tensorflow_datasets as tfds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data():\n",
    "    \"\"\"\n",
    "    loads data from local folder Data\n",
    "    converts the array.array objects to numpy ndarrays\n",
    "    \"\"\"\n",
    "    mndata = MNIST('./Data/MNIST_Data')\n",
    "    train_X, train_Y = mndata.load_training()\n",
    "    test_X, test_Y = mndata.load_testing()\n",
    "    train_X =np.asarray(train_X)\n",
    "    test_X = np.asarray(test_X)\n",
    "    train_Y = np.asarray(train_Y)\n",
    "    test_Y = np.asarray(test_Y)\n",
    "    return train_X, train_Y, test_X, test_Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_my_data():\n",
    "    \n",
    "    \"\"\"\n",
    "    loads data from local folder emilysdata\n",
    "    \"\"\"\n",
    "    myLabels = np.array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9])\n",
    "    myImages = np.zeros((10, 28, 28, 1), dtype=np.float32)\n",
    "    folderpath= \"Data/emily_data/numbers\"\n",
    "    filename = [\"zero\", \"one\", \"two\", \"three\", \"four\", \"five\", \"six\", \"seven\", \"eight\", \"nine\"]\n",
    "    for i in range(10):\n",
    "        color_img = cv2.imread(\"%s/%s.png\" % (folderpath, filename[i]))\n",
    "        gray_img = cv2.cvtColor(color_img, cv2.COLOR_BGR2GRAY)\n",
    "        # name = \"test_binary\" + str(i) + \".png\"\n",
    "        ret,binarized_img = cv2.threshold(gray_img,100,255,cv2.THRESH_BINARY_INV)\n",
    "        binarized_img = np.reshape(binarized_img, (28, 28, 1))\n",
    "        # cv2.imwrite(name, binarized_img)\n",
    "        myImages[i, :, :, :] = binarized_img\n",
    "    \n",
    "    return myImages, myLabels  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "img, lab = load_my_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_image_data(image_data):\n",
    "    \"\"\"\n",
    "    takes in an array object that is assumed to be X image data for MNIST.\n",
    "    reshape to get grayscale 28x28 images for each row.\n",
    "    converts array to float and normalizes values betweeen 0 and 1\n",
    "    \n",
    "    param image_data: a array.array object that is training or test data\n",
    "    return image_array_norm: normalized image array\n",
    "    \"\"\"\n",
    "    image_array = np.reshape(image_data, (image_data.shape[0], 28, 28, 1))\n",
    "    image_array = image_array.astype(np.float32)\n",
    "    image_array_norm = image_array / 255.0\n",
    "    return image_array_norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_label_data(label_data):\n",
    "    \"\"\"\n",
    "    takes in an array object and reshapes to 2D array. \n",
    "    One hot encodes labels since they are categorical.\n",
    "    \n",
    "    param label_data: label data\n",
    "    return encoded_labels: (-1,10) array of encoded data labels\n",
    "    \"\"\"\n",
    "    label_array = label_data.reshape(-1, 1)\n",
    "    hot_encoder = OneHotEncoder(dtype=np.uint8)\n",
    "    hot_encoder.fit(label_array)\n",
    "    encoded_labels = hot_encoder.transform(label_array).toarray()\n",
    "    return encoded_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find out if dataset is balanced \n",
    "def visualize_balance_of_dataset(y, name):\n",
    "    \"\"\"\n",
    "    output bar chart showing number of elements\n",
    "    for multiclass (0, 1, 2,...9). \n",
    "    \n",
    "    Used to visualize how balanced the data set is. \n",
    "    \n",
    "    param y: label array\n",
    "    \"\"\"\n",
    "    u, counts = np.unique(y, return_counts=True)\n",
    "    sum_counts = np.sum(counts)\n",
    "    distro_list = []\n",
    "    for i in counts:\n",
    "        distro =(i / sum_counts) * 100\n",
    "        distro_list.append(distro)\n",
    "    # print('distribution = ', distro_list)    \n",
    "    plt.figure(figsize=(10, 5))\n",
    "    if name == \"Train\":\n",
    "        col = \"blue\"\n",
    "    else:\n",
    "        col = \"red\"\n",
    "    plt.bar(u, counts, color=col)\n",
    "    plt.title(name + \" Dataset Distribution\")\n",
    "    plt.xticks(np.arange(min(u), max(u)+1, 1.0))\n",
    "    plt.xlabel(\"Label Values - Numerical Characters\")\n",
    "    plt.ylabel(\"Number of Label Value Occurrences\")\n",
    "    plt.savefig(name + \"_barChart.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_CNNmodel():\n",
    "    # add layers for CNN\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_uniform', input_shape=(28, 28, 1)))\n",
    "    model.add(MaxPooling2D((2, 2)))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(100, activation='relu', kernel_initializer='he_uniform'))\n",
    "    model.add(Dense(10, activation='softmax'))\n",
    "    \n",
    "    opt = SGD(lr=0.01, momentum=0.9)\n",
    "    model.compile(optimizer=opt, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_validate_model(Xtrain, Ytrain):\n",
    "    history_list = []\n",
    "    accuracy_list = []\n",
    "    kfold = KFold(n_splits=5, shuffle=True, random_state=10)\n",
    "    for i, j in kfold.split(Xtrain):\n",
    "        Xtrain_fold, Ytrain_fold = Xtrain[i], Ytrain[i]\n",
    "        XVal_fold, YVal_fold = Xtrain[j], Ytrain[j]\n",
    "        \n",
    "        cnn = create_CNNmodel()\n",
    "        history = cnn.fit(Xtrain_fold, Ytrain_fold, epochs=10, batch_size=32, validation_data=(XVal_fold, YVal_fold), verbose=0)\n",
    "        _, acc = cnn.evaluate(XVal_fold, YVal_fold, verbose=1)\n",
    "        \n",
    "        history_list.append(history)\n",
    "        accuracy_list.append(acc)\n",
    "        # print('accuracy = ', (acc * 100))\n",
    "    return history_list, accuracy_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_evaluate(Xtrain, Ytrain, Xtest, Ytest):\n",
    "    cnn = create_CNNmodel()\n",
    "    history = cnn.fit(Xtrain, Ytrain, batch_size=32, epochs=15, validation_split=0.1)\n",
    "    results = cnn.evaluate(Xtest, Ytest, verbose=1)\n",
    "    cnn.save('cnn_model')\n",
    "    return history, results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load MNIST data set\n",
    "def run_from_saved_model_with_Test_Data():\n",
    "    X_train_i, Y_train_i, X_test_i, Y_test_i = load_data() \n",
    "    \n",
    "    # preprocess training and test labels \n",
    "    Xtest = preprocess_image_data(X_test_i)\n",
    "    Ytest = preprocess_label_data(Y_test_i)\n",
    "    \n",
    "    # load pre-trained model\n",
    "    cnn = load_model('cnn_model')\n",
    "    results = cnn.evaluate(Xtest, Ytest, verbose=1)\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_from_beginning():\n",
    "    X_train_i, Y_train_i, X_test_i, Y_test_i = load_data()  # load data\n",
    "    \n",
    "    # preprocess training and test labels \n",
    "    Xtrain = preprocess_image_data(X_train_i)\n",
    "    Xtest = preprocess_image_data(X_test_i)\n",
    "    \n",
    "    Ytrain = preprocess_label_data(Y_train_i)\n",
    "    Ytest = preprocess_label_data(Y_test_i)\n",
    "    \n",
    "    # train and evaluate model using training and test data\n",
    "    history, results = train_evaluate(Xtrain, Ytrain, Xtest, Ytest)\n",
    "    \n",
    "    return history, results\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_from_saved_model_with_my_data():\n",
    "    x, y = load_my_data()\n",
    "    # preprocess training and test labels \n",
    "    X_data = preprocess_image_data(x)\n",
    "    Y_data = preprocess_label_data(y)\n",
    "    \n",
    "    # load pre-trained model\n",
    "    cnn = load_model('cnn_model')\n",
    "    results = cnn.evaluate(X_data, Y_data, verbose=1)\n",
    "    predictions = cnn.predict(X_data)\n",
    "    print('results', results)\n",
    "    # print('predictions', predictions)\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - 0s 14ms/step\n",
      "results [0.422191858291626, 0.800000011920929]\n",
      "predictions [[9.99993563e-01 1.36723870e-11 1.79051085e-07 5.84513438e-10\n",
      "  2.09913602e-13 5.47135492e-09 1.96993000e-09 5.52941538e-06\n",
      "  6.53251107e-07 6.76099461e-08]\n",
      " [2.35393666e-11 9.99998450e-01 1.24889743e-09 8.14682349e-11\n",
      "  1.37778818e-06 4.15465840e-09 1.39784335e-08 6.39289621e-10\n",
      "  6.93748561e-08 5.16587554e-12]\n",
      " [1.98959288e-17 3.80857672e-11 1.00000000e+00 3.81361401e-11\n",
      "  1.39120243e-25 5.32178124e-19 1.80802628e-22 9.06344277e-10\n",
      "  1.21788656e-11 2.37931724e-15]\n",
      " [2.67076470e-22 5.65474113e-15 2.62395747e-11 1.00000000e+00\n",
      "  5.57537104e-19 8.32973135e-11 1.17271560e-20 7.70321695e-10\n",
      "  3.62009762e-11 1.25702096e-11]\n",
      " [2.88916941e-14 1.57988961e-05 1.42890658e-10 1.63627919e-06\n",
      "  9.99963880e-01 4.66914019e-09 1.08661947e-10 8.24129458e-08\n",
      "  4.34636462e-07 1.81955911e-05]\n",
      " [1.91965618e-21 1.45065928e-20 5.77287502e-22 5.35493871e-10\n",
      "  1.05006007e-22 1.00000000e+00 3.39945615e-19 2.25828426e-23\n",
      "  2.37832690e-16 2.14926910e-10]\n",
      " [1.73706155e-07 5.90924201e-14 2.75349882e-10 4.14839763e-09\n",
      "  1.32429798e-12 6.56657445e-04 2.75916576e-01 6.02010439e-14\n",
      "  7.23426640e-01 1.85312418e-13]\n",
      " [2.12861701e-14 1.76263640e-07 1.21409562e-03 4.19522263e-02\n",
      "  2.91306023e-15 2.32418562e-16 5.02283887e-17 9.56832707e-01\n",
      "  7.78447713e-07 8.25253667e-12]\n",
      " [1.31805789e-10 7.27956237e-11 3.71196265e-08 9.28055584e-01\n",
      "  3.28146082e-12 9.42518508e-10 6.40024211e-08 1.28880897e-08\n",
      "  7.19442964e-02 1.82715293e-13]\n",
      " [4.13162976e-10 6.30000443e-07 6.02282228e-07 1.83874503e-01\n",
      "  5.30459511e-05 5.34821584e-06 2.21767313e-10 3.52461211e-04\n",
      "  4.32940833e-02 7.72419393e-01]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.422191858291626, 0.800000011920929]"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run_from_saved_model_with_my_data()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(48000, 28, 28, 1)\n",
      "Y (48000, 10)\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/resource_variable_ops.py:435: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "12000/12000 [==============================] - 3s 236us/step\n",
      "> 98.525\n",
      "(48000, 28, 28, 1)\n",
      "Y (48000, 10)\n",
      "12000/12000 [==============================] - 3s 272us/step\n",
      "> 98.750\n",
      "(48000, 28, 28, 1)\n",
      "Y (48000, 10)\n",
      "12000/12000 [==============================] - 3s 244us/step\n",
      "> 98.975\n",
      "(48000, 28, 28, 1)\n",
      "Y (48000, 10)\n",
      "12000/12000 [==============================] - 3s 214us/step\n",
      "> 98.608\n",
      "(48000, 28, 28, 1)\n",
      "Y (48000, 10)\n",
      "12000/12000 [==============================] - 3s 276us/step\n",
      "> 98.542\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 54000 samples, validate on 6000 samples\n",
      "Epoch 1/15\n",
      "54000/54000 [==============================] - 29s 543us/step - loss: 0.1734 - accuracy: 0.9465 - val_loss: 0.0653 - val_accuracy: 0.9825\n",
      "Epoch 2/15\n",
      "54000/54000 [==============================] - 29s 530us/step - loss: 0.0588 - accuracy: 0.9824 - val_loss: 0.0505 - val_accuracy: 0.9878\n",
      "Epoch 3/15\n",
      "54000/54000 [==============================] - 28s 528us/step - loss: 0.0378 - accuracy: 0.9883 - val_loss: 0.0490 - val_accuracy: 0.9885\n",
      "Epoch 4/15\n",
      "54000/54000 [==============================] - 29s 543us/step - loss: 0.0259 - accuracy: 0.9921 - val_loss: 0.0509 - val_accuracy: 0.9863\n",
      "Epoch 5/15\n",
      "54000/54000 [==============================] - 30s 554us/step - loss: 0.0174 - accuracy: 0.9946 - val_loss: 0.0436 - val_accuracy: 0.9877\n",
      "Epoch 6/15\n",
      "54000/54000 [==============================] - 31s 572us/step - loss: 0.0119 - accuracy: 0.9968 - val_loss: 0.0453 - val_accuracy: 0.9888\n",
      "Epoch 7/15\n",
      "54000/54000 [==============================] - 30s 558us/step - loss: 0.0082 - accuracy: 0.9981 - val_loss: 0.0480 - val_accuracy: 0.9875\n",
      "Epoch 8/15\n",
      "54000/54000 [==============================] - 30s 547us/step - loss: 0.0054 - accuracy: 0.9988 - val_loss: 0.0539 - val_accuracy: 0.9863\n",
      "Epoch 9/15\n",
      "54000/54000 [==============================] - 27s 503us/step - loss: 0.0034 - accuracy: 0.9994 - val_loss: 0.0439 - val_accuracy: 0.9897\n",
      "Epoch 10/15\n",
      "54000/54000 [==============================] - 31s 577us/step - loss: 0.0024 - accuracy: 0.9995 - val_loss: 0.0452 - val_accuracy: 0.9887\n",
      "Epoch 11/15\n",
      "54000/54000 [==============================] - 35s 640us/step - loss: 0.0017 - accuracy: 0.9999 - val_loss: 0.0481 - val_accuracy: 0.9893\n",
      "Epoch 12/15\n",
      "54000/54000 [==============================] - 32s 592us/step - loss: 0.0010 - accuracy: 0.9999 - val_loss: 0.0458 - val_accuracy: 0.9893\n",
      "Epoch 13/15\n",
      "54000/54000 [==============================] - 32s 586us/step - loss: 8.7772e-04 - accuracy: 0.9999 - val_loss: 0.0469 - val_accuracy: 0.9892\n",
      "Epoch 14/15\n",
      "54000/54000 [==============================] - 32s 584us/step - loss: 6.2014e-04 - accuracy: 1.0000 - val_loss: 0.0487 - val_accuracy: 0.9892\n",
      "Epoch 15/15\n",
      "54000/54000 [==============================] - 33s 610us/step - loss: 5.1649e-04 - accuracy: 1.0000 - val_loss: 0.0481 - val_accuracy: 0.9888\n",
      "10000/10000 [==============================] - 3s 317us/step\n",
      "accuracy 0.99\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_10\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_10 (Conv2D)           (None, 26, 26, 32)        320       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_10 (MaxPooling (None, 13, 13, 32)        0         \n",
      "_________________________________________________________________\n",
      "flatten_10 (Flatten)         (None, 5408)              0         \n",
      "_________________________________________________________________\n",
      "dense_19 (Dense)             (None, 100)               540900    \n",
      "_________________________________________________________________\n",
      "dense_20 (Dense)             (None, 10)                1010      \n",
      "=================================================================\n",
      "Total params: 542,230\n",
      "Trainable params: 542,230\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
