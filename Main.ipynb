{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:528: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:529: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:530: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:535: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import sys\n",
    "import cv2\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from mnist import MNIST\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "#from sklearn.model_selection import StratifiedKFold\n",
    "# from tensorflow import keras\n",
    "from keras.models import load_model\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D\n",
    "from keras.layers import MaxPooling2D\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Flatten\n",
    "from keras.optimizers import SGD\n",
    "#import tensorflow_datasets as tfds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data():\n",
    "    \"\"\"\n",
    "    loads data from local folder Data\n",
    "    converts the array.array objects to numpy ndarrays\n",
    "    \"\"\"\n",
    "    mndata = MNIST('./Data/MNIST_Data')\n",
    "    train_X, train_Y = mndata.load_training()\n",
    "    test_X, test_Y = mndata.load_testing()\n",
    "    train_X =np.asarray(train_X)\n",
    "    test_X = np.asarray(test_X)\n",
    "    train_Y = np.asarray(train_Y)\n",
    "    test_Y = np.asarray(test_Y)\n",
    "    return train_X, train_Y, test_X, test_Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_my_data():\n",
    "    \n",
    "    \"\"\"\n",
    "    loads data from local folder emilysdata\n",
    "    \"\"\"\n",
    "    myLabels = np.array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9])\n",
    "    myImages = np.zeros((10, 28, 28, 1), dtype=np.float32)\n",
    "    folderpath= \"Data/emily_data/numbers\"\n",
    "    filename = [\"zero\", \"one\", \"two\", \"three\", \"four\", \"five\", \"six\", \"seven\", \"eight\", \"nine\"]\n",
    "    for i in range(10):\n",
    "        color_img = cv2.imread(\"%s/%s.png\" % (folderpath, filename[i]))\n",
    "        gray_img = cv2.cvtColor(color_img, cv2.COLOR_BGR2GRAY)\n",
    "        # name = \"test_binary\" + str(i) + \".png\"\n",
    "        ret,binarized_img = cv2.threshold(gray_img,100,255,cv2.THRESH_BINARY_INV)\n",
    "        binarized_img = np.reshape(binarized_img, (28, 28, 1))\n",
    "        # cv2.imwrite(name, binarized_img)\n",
    "        myImages[i, :, :, :] = binarized_img\n",
    "    \n",
    "    return myImages, myLabels  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img, lab = load_my_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_image_data(image_data):\n",
    "    \"\"\"\n",
    "    takes in an array object that is assumed to be X image data for MNIST.\n",
    "    reshape to get grayscale 28x28 images for each row.\n",
    "    converts array to float and normalizes values betweeen 0 and 1\n",
    "    \n",
    "    param image_data: a array.array object that is training or test data\n",
    "    return image_array_norm: normalized image array\n",
    "    \"\"\"\n",
    "    image_array = np.reshape(image_data, (image_data.shape[0], 28, 28, 1))\n",
    "    image_array = image_array.astype(np.float32)\n",
    "    image_array_norm = image_array / 255.0\n",
    "    return image_array_norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_label_data(label_data):\n",
    "    \"\"\"\n",
    "    takes in an array object and reshapes to 2D array. \n",
    "    One hot encodes labels since they are categorical.\n",
    "    \n",
    "    param label_data: label data\n",
    "    return encoded_labels: (-1,10) array of encoded data labels\n",
    "    \"\"\"\n",
    "    label_array = label_data.reshape(-1, 1)\n",
    "    hot_encoder = OneHotEncoder(dtype=np.uint8)\n",
    "    hot_encoder.fit(label_array)\n",
    "    encoded_labels = hot_encoder.transform(label_array).toarray()\n",
    "    return encoded_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find out if dataset is balanced \n",
    "def visualize_balance_of_dataset(y, name):\n",
    "    \"\"\"\n",
    "    output bar chart showing number of elements\n",
    "    for multiclass (0, 1, 2,...9). \n",
    "    \n",
    "    Used to visualize how balanced the data set is. \n",
    "    \n",
    "    param y: label array\n",
    "    \"\"\"\n",
    "    u, counts = np.unique(y, return_counts=True)\n",
    "    sum_counts = np.sum(counts)\n",
    "    distro_list = []\n",
    "    for i in counts:\n",
    "        distro =(i / sum_counts) * 100\n",
    "        distro_list.append(distro)\n",
    "    # print('distribution = ', distro_list)    \n",
    "    plt.figure(figsize=(10, 5))\n",
    "    if name == \"Train\":\n",
    "        col = \"blue\"\n",
    "    else:\n",
    "        col = \"red\"\n",
    "    plt.bar(u, counts, color=col)\n",
    "    plt.title(name + \" Dataset Distribution\")\n",
    "    plt.xticks(np.arange(min(u), max(u)+1, 1.0))\n",
    "    plt.xlabel(\"Label Categories - Numerical Characters\")\n",
    "    plt.ylabel(\"Number of Label Category Occurrences\")\n",
    "    plt.savefig(name + \"_barChart.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_CNNmodel():\n",
    "    \n",
    "    \"\"\"\n",
    "    Creates the CNN model \n",
    "    \n",
    "    return model\n",
    "    \"\"\"\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_uniform', input_shape=(28, 28, 1)))\n",
    "    model.add(MaxPooling2D((2, 2)))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(100, activation='relu', kernel_initializer='he_uniform'))\n",
    "    model.add(Dense(10, activation='softmax'))\n",
    "    \n",
    "    opt = SGD(lr=0.01, momentum=0.9)\n",
    "    model.compile(optimizer=opt, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_validate_model(Xtrain, Ytrain):\n",
    "    \"\"\"\n",
    "    A function to perform KFold cross validation on the data\n",
    "    \n",
    "    param Xtrain: the training image data\n",
    "    param Ytrain: the labels for the training image data\n",
    "    \n",
    "    return history_list, accuracy_list : loss and accuracy for each Kfold iteration\n",
    "    \"\"\"\n",
    "    history_list = []\n",
    "    accuracy_list = []\n",
    "    kfold = KFold(n_splits=5, shuffle=True, random_state=10)\n",
    "    for i, j in kfold.split(Xtrain):\n",
    "        Xtrain_fold, Ytrain_fold = Xtrain[i], Ytrain[i]\n",
    "        XVal_fold, YVal_fold = Xtrain[j], Ytrain[j]\n",
    "        \n",
    "        cnn = create_CNNmodel()\n",
    "        history = cnn.fit(Xtrain_fold, Ytrain_fold, epochs=10, batch_size=32, validation_data=(XVal_fold, YVal_fold), verbose=0)\n",
    "        _, acc = cnn.evaluate(XVal_fold, YVal_fold, verbose=1)\n",
    "        \n",
    "        history_list.append(history)\n",
    "        accuracy_list.append(acc)\n",
    "        print('accuracy = ', (acc * 100))\n",
    "    return history_list, accuracy_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_evaluate(Xtrain, Ytrain, Xtest, Ytest):\n",
    "    \"\"\"\n",
    "    trains the model with the entire training set (assumes that cross validation produced good results).\n",
    "    Evaluates model on Test data provided by MNIST\n",
    "    \n",
    "    param: Xtrain, Ytrain, Xtest, Ytest: training and test data\n",
    "    return history, results: loss and accuracy \n",
    "    \"\"\"\n",
    "    cnn = create_CNNmodel()\n",
    "    history = cnn.fit(Xtrain, Ytrain, batch_size=32, epochs=15, validation_split=0.1)\n",
    "    results = cnn.evaluate(Xtest, Ytest, verbose=1)\n",
    "    cnn.save('cnn_model_new')\n",
    "    return history, results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load MNIST data set\n",
    "def run_from_saved_model_with_Test_Data():\n",
    "    \"\"\"\n",
    "    loads pre-trained model and evaluates the model using the MNIST test data\n",
    "    \n",
    "    return results: accuracy of model on test data\n",
    "    \"\"\"\n",
    "    X_train_i, Y_train_i, X_test_i, Y_test_i = load_data() \n",
    "    \n",
    "    # preprocess training and test labels \n",
    "    Xtest = preprocess_image_data(X_test_i)\n",
    "    Ytest = preprocess_label_data(Y_test_i)\n",
    "    \n",
    "    # load pre-trained model\n",
    "    cnn = load_model('cnn_model')\n",
    "    results = cnn.evaluate(Xtest, Ytest, verbose=1)\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_from_beginning():\n",
    "    \"\"\"\n",
    "    option to train model from scratch and then evaluates using MNIST test data\n",
    "    \"\"\"\n",
    "    X_train_i, Y_train_i, X_test_i, Y_test_i = load_data()  # load data\n",
    "    \n",
    "    # preprocess training and test labels \n",
    "    Xtrain = preprocess_image_data(X_train_i)\n",
    "    Xtest = preprocess_image_data(X_test_i)\n",
    "    \n",
    "    Ytrain = preprocess_label_data(Y_train_i)\n",
    "    Ytest = preprocess_label_data(Y_test_i)\n",
    "    \n",
    "    # train and evaluate model using training and test data\n",
    "    history, results = train_evaluate(Xtrain, Ytrain, Xtest, Ytest)\n",
    "    \n",
    "    return history, results\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_from_saved_model_with_my_data():\n",
    "    \"\"\"\n",
    "    loads pre-trained model and evaluates the model in my personally created handwritten\n",
    "    number dataset\n",
    "    \"\"\"\n",
    "    x, y = load_my_data()\n",
    "    # preprocess training and test labels \n",
    "    X_data = preprocess_image_data(x)\n",
    "    Y_data = preprocess_label_data(y)\n",
    "    \n",
    "    # load pre-trained model\n",
    "    cnn = load_model('cnn_model')\n",
    "    results = cnn.evaluate(X_data, Y_data, verbose=1)\n",
    "    predictions = cnn.predict(X_data)\n",
    "    print('results', results)\n",
    "    # print('predictions', predictions)\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_cross_validation():\n",
    "     \"\"\"\n",
    "    loads pre-trained model and evaluates the model using the MNIST test data\n",
    "    \n",
    "    return results: accuracy of model on test data\n",
    "    \"\"\"\n",
    "    X_train_i, Y_train_i, X_test_i, Y_test_i = load_data() \n",
    "    \n",
    "    # preprocess training and test labels\n",
    "    Xtrain = preprocess_image_data(X_train_i)\n",
    "    Ytrain = preprocess_label_data(Y_train_i)\n",
    "\n",
    "    cross_validate_model(Xtrain, Ytrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    # print command line arguments\n",
    "    for arg in sys.argv[1:]:\n",
    "        if arg == 1:\n",
    "            print(\"running pre-trained model on Test Data\")\n",
    "            result = run_from_saved_model_with_Test_Data()\n",
    "            print('results from saved model and Test Data = ', result)\n",
    "        if arg == 2:\n",
    "            print(\"running pre-trained model on the data I created\")\n",
    "            results = run_from_saved_model_with_my_data()\n",
    "            print(\"results from saved model and my Data = \", results)\n",
    "        if arg == 3:\n",
    "            print(\"training  model and testing model with Test Data\")\n",
    "            h, r = run_from_beginning()\n",
    "            print('history = ', h)\n",
    "            print('results = ', r)\n",
    "        if arg == 4:\n",
    "            print(\"running cross validation on training data\")\n",
    "            run_cross_validation()\n",
    "        if arg == 5:\n",
    "            print('creating and saving bar chart that shows distribution of categories')\n",
    "            X_train_i, Y_train_i, X_test_i, Y_test_i = load_data()\n",
    "            visualize_balance_of_dataset(Y_train_i, \"Train\")\n",
    "            visualize_balance_of_dataset(Y_test_i, \"Test\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
